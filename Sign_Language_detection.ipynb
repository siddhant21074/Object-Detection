{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1 : Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2 : Using MP Holistic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic    \n",
    "mp_drawing = mp.solutions.drawing_utils \n",
    "mp_face_mesh = mp.solutions.face_mesh "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "MediaPipe Holistic is a tool that tracks the whole human body, including:\n",
    "\n",
    "    Body Pose: Tracks 33 keypoints on the body (e.g., head, arms, legs).\n",
    "    Face: Tracks 468 detailed points on the face (e.g., eyes, mouth, nose).\n",
    "    Hands: Tracks 21 keypoints on each hand.\n",
    "\n",
    "MediaPipe drawing_utils : \n",
    "\n",
    "    is a tool that helps you draw points and lines on images or video frames to show the landmarks (like body joints, face features, or hand points) detected by MediaPipe models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Images will be provided from opencv in the form of Frames\n",
    "# Why to convert from BGR to RGB : If the conversion is skipped, MediaPipe might produce incorrect outputs, as its models and pipelines # # are trained and optimized for RGB images.\n",
    "\n",
    "def mediapipe_detection(image,model):\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)  # color conversion from bgr to rgb\n",
    "    image.flags.writeable = False                   # sets the image writeable status to false \n",
    "    results = model.process(image)               # Image is actually detected here using mediapipe \n",
    "    image.flags.writeable = True                    # Again the image is set it writeable\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)  # color conversion from rgb to bgr\n",
    "    return image,results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image,results):\n",
    "    \n",
    "    # Here we are making a customized drawing lines \n",
    "    landmark_drawing_spec = mp_drawing.DrawingSpec(color=(80, 110, 10), thickness=1, circle_radius=1)\n",
    "    connection_drawing_spec = mp_drawing.DrawingSpec(color=(80, 256, 121), thickness=1, circle_radius=1)\n",
    "    \n",
    "    landmark_drawing_spec1 = mp_drawing.DrawingSpec(color=(466,466,466), thickness=1, circle_radius=4)\n",
    "    connection_drawing_spec1 = mp_drawing.DrawingSpec(color=(000, 000, 000), thickness=1, circle_radius=2)\n",
    "   \n",
    "    \n",
    "    # This will draw the face ,pose and hands connection\n",
    "    \n",
    "    mp_drawing.draw_landmarks(image,results.face_landmarks,mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                              landmark_drawing_spec,connection_drawing_spec)\n",
    "    \n",
    "    mp_drawing.draw_landmarks(image,results.pose_landmarks,mp_holistic.POSE_CONNECTIONS,\n",
    "                              landmark_drawing_spec1,connection_drawing_spec1)\n",
    "    \n",
    "    mp_drawing.draw_landmarks(image,results.left_hand_landmarks,mp_holistic.HAND_CONNECTIONS,\n",
    "                              landmark_drawing_spec1,connection_drawing_spec1)\n",
    "    \n",
    "    mp_drawing.draw_landmarks(image,results.right_hand_landmarks,mp_holistic.HAND_CONNECTIONS,\n",
    "                               landmark_drawing_spec1,connection_drawing_spec1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "original basic code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(0)\n",
    "# with mp_holistic.Holistic(min_detection_confidence=0.5,min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "#     # min_detection - initially the holistic will detect the image with initial detection confidence\n",
    "#     # min_tracking_confidence - holistic will detect the image with after initial  detection confidence\n",
    "    \n",
    "    \n",
    "#     while cap.isOpened():\n",
    "\n",
    "#         # after capturing the video in real time the read() function return 2 values - 1 is return value and 2nd is the frame \n",
    "#         res,frame = cap.read()\n",
    "\n",
    "#         # Using a function to make detection \n",
    "#         image,results = mediapipe_detection(frame,holistic)\n",
    "\n",
    "#         # Draw landmarks in real time\n",
    "#         draw_landmarks(image,results)\n",
    "        \n",
    "#         cv2.imshow('Opencv_video',image)\n",
    "#         # Breaking our infinite loop of capturing the video\n",
    "    \n",
    "#         if cv2.waitKey(10) & 0xff == ord('q'):  # pressing q on keyboard will quite from video \n",
    "#             break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results.face_landmarks\n",
    "# Here the x and y are the x and y axis position and z will be the relatice distance from camera to object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(cv2.cvtColor(frame ,cv2.COLOR_BGR2RGB)) # converted to original form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3 : Extracting the Keypoint Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Here we are storing the x,y and z cordinates of pose \n",
    "# Flatten function :  is used to convert a multi-dimensional data structure (e.g., a list of lists or an array) into a 1D structure.\n",
    "\n",
    "def extracted_values(results):\n",
    "    pose = np.array([[res.x,res.y,res.z,res.visibility]for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "\n",
    "    face = np.array([[res.x,res.y,res.z]for res in results.face_landmarks.landmark]).flatten()if results.face_landmarks else np.zeros(468*3)\n",
    "\n",
    "    left_hand = np.array([[res.x,res.y,res.z]for res in results.left_hand_landmarks.landmark]).flatten()if results.left_hand_landmarks else np.zeros(21*3)\n",
    "\n",
    "    right_hand = np.array([[res.x,res.y,res.z]for res in results.right_hand_landmarks.landmark]).flatten()if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose,face,left_hand,right_hand])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the each frames in numpy array\n",
    "result_test = extracted_values(results)\n",
    "np.save('0',result_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4 : Setup Folders for collection \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the folders \n",
    "\n",
    "Data_path = os.path.join(\"MP_DATA\")   #  ensures the correct folder structure is created on your operating system.\n",
    "actions = np.array(['hello','thanks','namaste'])\n",
    "no_squences = 30  \n",
    "sequence_length = 30  # containing the video of 30 frames \n",
    "\n",
    "for action in actions:\n",
    "    for sequence in range(no_squences):\n",
    "        try:\n",
    "            os.makedirs(os.path.join(Data_path,action,str(sequence)))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5 : Collect Keypoints Values for Training and Testing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this code for training and adding another actions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5,min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    # min_detection - initially the holistic will detect the image with initial detection confidence\n",
    "    # min_tracking_confidence - holistic will detect the image with after initial  detection confidence\n",
    "    for action in actions:\n",
    "        for sequence in range(no_squences):\n",
    "            for frame_num in range(sequence_length):\n",
    "                \n",
    "                # after capturing the video in real time the read() function return 2 values - 1 is return value and 2nd is the frame \n",
    "                res,frame = cap.read()\n",
    "\n",
    "                # Using a function to make detection \n",
    "                image,results = mediapipe_detection(frame,holistic)\n",
    "                \n",
    "                # Draw landmarks in real time\n",
    "                draw_landmarks(image,results)\n",
    "                \n",
    "                if frame_num == 0:\n",
    "                    cv2.putText(image,'STARTING COLLECTION',(120,200),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX,1,(0,255,0),4,cv2.LINE_AA)\n",
    "                    cv2.putText(image,'Collecting frames for {} video number{} '.format(action,sequence),(15,12),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,255),1,cv2.LINE_AA)\n",
    "                    \n",
    "                    cv2.waitKey(2000)\n",
    "                else:\n",
    "                    cv2.putText(image,'Collecting frames for {} video number '.format(action,sequence),(15,12),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,255),1,cv2.LINE_AA)\n",
    "                \n",
    "                # Export keypoints\n",
    "                                    \n",
    "                keypoints = extracted_values(results)\n",
    "                npy_path = os.path.join(Data_path,action,str(sequence),str(frame_num))\n",
    "                np.save(npy_path,keypoints)\n",
    "                \n",
    "                cv2.imshow('Opencv_video',image)\n",
    "                # Breaking our infinite loop of capturing the video\n",
    "            \n",
    "                if cv2.waitKey(10) & 0xff == ord('q'):  # pressing q on keyboard will quite from video \n",
    "                    break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 6 : Preprocess Data and Create Labels and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hello': 0, 'thanks': 1, 'namaste': 2}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "label_map = {label:num for num,label in enumerate(actions)}\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping throught each frame and adding it to array\n",
    "\n",
    "sequences,labels = [],[]\n",
    "for action in actions:\n",
    "    for sequence in range(no_squences):\n",
    "        window = []\n",
    "        for frame_num in range(sequence_length):\n",
    "            res = np.load(os.path.join(Data_path,action,str(sequence),\"{}.npy\".format(frame_num)))\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining x and y variables for training model\n",
    "x = np.array(sequences)\n",
    "y = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 30, 1662)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape\n",
    "# Here 60 videos with 30 frames each and 1662 keypoints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 7 : Build and Train LSTM Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(\"Logs\")\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()  # object of Squential class\n",
    "\n",
    "# Addeding  a neural network layers and returinig to other layers \n",
    " \n",
    "model.add(LSTM(64,return_sequences=True,activation='relu',input_shape=(30,1662))) \n",
    "model.add(LSTM(128,return_sequences=True,activation='relu'))\n",
    "model.add(LSTM(64,return_sequences=False,activation='relu'))\n",
    "\n",
    "# not returing to layer because the other next layer is the dense layer \n",
    "# the number specified - 64 ,128 and etc are the units \n",
    "# input shape is our x data shape with 30 frames and 1662 keypoints \n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(actions.shape[0],activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling our model \n",
    "# We have  multiclass classification therefore use loss='categor...\n",
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "3/3 [==============================] - 4s 152ms/step - loss: 3.6706 - categorical_accuracy: 0.4353\n",
      "Epoch 2/2000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 5.7126 - categorical_accuracy: 0.3529\n",
      "Epoch 3/2000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 3.8266 - categorical_accuracy: 0.2588\n",
      "Epoch 4/2000\n",
      "3/3 [==============================] - 1s 191ms/step - loss: 4.0265 - categorical_accuracy: 0.3059\n",
      "Epoch 5/2000\n",
      "3/3 [==============================] - 1s 176ms/step - loss: 1.5023 - categorical_accuracy: 0.3882\n",
      "Epoch 6/2000\n",
      "3/3 [==============================] - 1s 162ms/step - loss: 1.3863 - categorical_accuracy: 0.1765\n",
      "Epoch 7/2000\n",
      "3/3 [==============================] - 1s 182ms/step - loss: 1.1287 - categorical_accuracy: 0.2706\n",
      "Epoch 8/2000\n",
      "3/3 [==============================] - 1s 161ms/step - loss: 1.1215 - categorical_accuracy: 0.3176\n",
      "Epoch 9/2000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 1.0929 - categorical_accuracy: 0.3294\n",
      "Epoch 10/2000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 1.0472 - categorical_accuracy: 0.3529\n",
      "Epoch 11/2000\n",
      "3/3 [==============================] - 1s 189ms/step - loss: 0.9705 - categorical_accuracy: 0.5176\n",
      "Epoch 12/2000\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 1.1182 - categorical_accuracy: 0.4000\n",
      "Epoch 13/2000\n",
      "3/3 [==============================] - 1s 167ms/step - loss: 0.9747 - categorical_accuracy: 0.5294\n",
      "Epoch 14/2000\n",
      "3/3 [==============================] - 1s 168ms/step - loss: 0.8695 - categorical_accuracy: 0.4824\n",
      "Epoch 15/2000\n",
      "3/3 [==============================] - 1s 163ms/step - loss: 1.0153 - categorical_accuracy: 0.4824\n",
      "Epoch 16/2000\n",
      "3/3 [==============================] - 1s 163ms/step - loss: 0.8704 - categorical_accuracy: 0.6471\n",
      "Epoch 17/2000\n",
      "3/3 [==============================] - 1s 168ms/step - loss: 1.7391 - categorical_accuracy: 0.3529\n",
      "Epoch 18/2000\n",
      "3/3 [==============================] - 1s 204ms/step - loss: 1.9781 - categorical_accuracy: 0.3529\n",
      "Epoch 19/2000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 1.4268 - categorical_accuracy: 0.4706\n",
      "Epoch 20/2000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 1.1208 - categorical_accuracy: 0.3647\n",
      "Epoch 21/2000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 1.1411 - categorical_accuracy: 0.3529\n",
      "Epoch 22/2000\n",
      "3/3 [==============================] - 1s 166ms/step - loss: 1.1234 - categorical_accuracy: 0.3294\n",
      "Epoch 23/2000\n",
      "3/3 [==============================] - 1s 145ms/step - loss: 1.0970 - categorical_accuracy: 0.3529\n",
      "Epoch 24/2000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 1.0760 - categorical_accuracy: 0.3529\n",
      "Epoch 25/2000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 1.0677 - categorical_accuracy: 0.3529\n",
      "Epoch 26/2000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 1.0538 - categorical_accuracy: 0.3765\n",
      "Epoch 27/2000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 1.0448 - categorical_accuracy: 0.4118\n",
      "Epoch 28/2000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 1.0283 - categorical_accuracy: 0.5059\n",
      "Epoch 29/2000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 1.0049 - categorical_accuracy: 0.4824\n",
      "Epoch 30/2000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 1.0302 - categorical_accuracy: 0.5176\n",
      "Epoch 31/2000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 1.2041 - categorical_accuracy: 0.4941\n",
      "Epoch 32/2000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 1.0229 - categorical_accuracy: 0.6471\n",
      "Epoch 33/2000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 1.0281 - categorical_accuracy: 0.7294\n",
      "Epoch 34/2000\n",
      "3/3 [==============================] - 1s 165ms/step - loss: 1.0275 - categorical_accuracy: 0.7059\n",
      "Epoch 35/2000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 1.0207 - categorical_accuracy: 0.6118\n",
      "Epoch 36/2000\n",
      "3/3 [==============================] - 1s 159ms/step - loss: 0.9870 - categorical_accuracy: 0.5882\n",
      "Epoch 37/2000\n",
      "3/3 [==============================] - 1s 166ms/step - loss: 0.9236 - categorical_accuracy: 0.6353\n",
      "Epoch 38/2000\n",
      "3/3 [==============================] - 0s 155ms/step - loss: 0.8196 - categorical_accuracy: 0.6235\n",
      "Epoch 39/2000\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.7559 - categorical_accuracy: 0.6824\n",
      "Epoch 40/2000\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 1.9074 - categorical_accuracy: 0.5176\n",
      "Epoch 41/2000\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 1.1925 - categorical_accuracy: 0.3412\n",
      "Epoch 42/2000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 1.6467 - categorical_accuracy: 0.3647\n",
      "Epoch 43/2000\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 1.0914 - categorical_accuracy: 0.4471\n",
      "Epoch 44/2000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 1.0765 - categorical_accuracy: 0.3882\n",
      "Epoch 45/2000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 1.0756 - categorical_accuracy: 0.3882\n",
      "Epoch 46/2000\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 1.0251 - categorical_accuracy: 0.4706\n",
      "Epoch 47/2000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 1.0105 - categorical_accuracy: 0.5765\n",
      "Epoch 48/2000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.9824 - categorical_accuracy: 0.5294\n",
      "Epoch 49/2000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.9587 - categorical_accuracy: 0.5176\n",
      "Epoch 50/2000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.9282 - categorical_accuracy: 0.7412\n",
      "Epoch 51/2000\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.8816 - categorical_accuracy: 0.5647\n",
      "Epoch 52/2000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.8552 - categorical_accuracy: 0.6471\n",
      "Epoch 53/2000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.7686 - categorical_accuracy: 0.7765\n",
      "Epoch 54/2000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.6777 - categorical_accuracy: 0.8471\n",
      "Epoch 55/2000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.9613 - categorical_accuracy: 0.5529\n",
      "Epoch 56/2000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 1.3437 - categorical_accuracy: 0.5059\n",
      "Epoch 57/2000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.7552 - categorical_accuracy: 0.6118\n",
      "Epoch 58/2000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.8408 - categorical_accuracy: 0.5294\n",
      "Epoch 59/2000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.7485 - categorical_accuracy: 0.7412\n",
      "Epoch 60/2000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.7456 - categorical_accuracy: 0.8118\n",
      "Epoch 61/2000\n",
      "3/3 [==============================] - 0s 152ms/step - loss: 0.7319 - categorical_accuracy: 0.7765\n",
      "Epoch 62/2000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.6588 - categorical_accuracy: 0.7412\n",
      "Epoch 63/2000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.6564 - categorical_accuracy: 0.8000\n",
      "Epoch 64/2000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.5473 - categorical_accuracy: 0.8118\n",
      "Epoch 65/2000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.5909 - categorical_accuracy: 0.6941\n",
      "Epoch 66/2000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.4824 - categorical_accuracy: 0.8118\n",
      "Epoch 67/2000\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.4729 - categorical_accuracy: 0.7765\n",
      "Epoch 68/2000\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.4958 - categorical_accuracy: 0.7529\n",
      "Epoch 69/2000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.5253 - categorical_accuracy: 0.8353\n",
      "Epoch 70/2000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.3865 - categorical_accuracy: 0.8588\n",
      "Epoch 71/2000\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.3798 - categorical_accuracy: 0.8471\n",
      "Epoch 72/2000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.3877 - categorical_accuracy: 0.8353\n",
      "Epoch 73/2000\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.3845 - categorical_accuracy: 0.8588\n",
      "Epoch 74/2000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.3641 - categorical_accuracy: 0.8353\n",
      "Epoch 75/2000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 0.4451 - categorical_accuracy: 0.7765\n",
      "Epoch 76/2000\n",
      "3/3 [==============================] - 1s 186ms/step - loss: 0.4284 - categorical_accuracy: 0.8118\n",
      "Epoch 77/2000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.3091 - categorical_accuracy: 0.8706\n",
      "Epoch 78/2000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.3293 - categorical_accuracy: 0.8471\n",
      "Epoch 79/2000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.3731 - categorical_accuracy: 0.8353\n",
      "Epoch 80/2000\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.2937 - categorical_accuracy: 0.8941\n",
      "Epoch 81/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.3703 - categorical_accuracy: 0.8471\n",
      "Epoch 82/2000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.2896 - categorical_accuracy: 0.8941\n",
      "Epoch 83/2000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.2870 - categorical_accuracy: 0.8824\n",
      "Epoch 84/2000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2423 - categorical_accuracy: 0.9176\n",
      "Epoch 85/2000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.2665 - categorical_accuracy: 0.8941\n",
      "Epoch 86/2000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2568 - categorical_accuracy: 0.9294\n",
      "Epoch 87/2000\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.2285 - categorical_accuracy: 0.9059\n",
      "Epoch 88/2000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.4517 - categorical_accuracy: 0.8000\n",
      "Epoch 89/2000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.3638 - categorical_accuracy: 0.8588\n",
      "Epoch 90/2000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2603 - categorical_accuracy: 0.8706\n",
      "Epoch 91/2000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.4323 - categorical_accuracy: 0.8000\n",
      "Epoch 92/2000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3535 - categorical_accuracy: 0.8353\n",
      "Epoch 93/2000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2792 - categorical_accuracy: 0.9059\n",
      "Epoch 94/2000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.4283 - categorical_accuracy: 0.8353\n",
      "Epoch 95/2000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3356 - categorical_accuracy: 0.8824\n",
      "Epoch 96/2000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2726 - categorical_accuracy: 0.8941\n",
      "Epoch 97/2000\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.2440 - categorical_accuracy: 0.9412\n",
      "Epoch 98/2000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2361 - categorical_accuracy: 0.9294\n",
      "Epoch 99/2000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2476 - categorical_accuracy: 0.8706\n",
      "Epoch 100/2000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2668 - categorical_accuracy: 0.9059\n",
      "Epoch 101/2000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2258 - categorical_accuracy: 0.9059\n",
      "Epoch 102/2000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.4331 - categorical_accuracy: 0.8471\n",
      "Epoch 103/2000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.5278 - categorical_accuracy: 0.7529\n",
      "Epoch 104/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.3346 - categorical_accuracy: 0.8353\n",
      "Epoch 105/2000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2828 - categorical_accuracy: 0.8588\n",
      "Epoch 106/2000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2788 - categorical_accuracy: 0.8941\n",
      "Epoch 107/2000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2554 - categorical_accuracy: 0.9059\n",
      "Epoch 108/2000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.2663 - categorical_accuracy: 0.8941\n",
      "Epoch 109/2000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2570 - categorical_accuracy: 0.8941\n",
      "Epoch 110/2000\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 0.2156 - categorical_accuracy: 0.9294\n",
      "Epoch 111/2000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.2472 - categorical_accuracy: 0.9059\n",
      "Epoch 112/2000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.2292 - categorical_accuracy: 0.9059\n",
      "Epoch 113/2000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.3234 - categorical_accuracy: 0.8706\n",
      "Epoch 114/2000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.2697 - categorical_accuracy: 0.8824\n",
      "Epoch 115/2000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.2548 - categorical_accuracy: 0.8824\n",
      "Epoch 116/2000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.2328 - categorical_accuracy: 0.8824\n",
      "Epoch 117/2000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.3046 - categorical_accuracy: 0.8941\n",
      "Epoch 118/2000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.2518 - categorical_accuracy: 0.9059\n",
      "Epoch 119/2000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2295 - categorical_accuracy: 0.8941\n",
      "Epoch 120/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2222 - categorical_accuracy: 0.9294\n",
      "Epoch 121/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2736 - categorical_accuracy: 0.8824\n",
      "Epoch 122/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2576 - categorical_accuracy: 0.8941\n",
      "Epoch 123/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2518 - categorical_accuracy: 0.8824\n",
      "Epoch 124/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2163 - categorical_accuracy: 0.9059\n",
      "Epoch 125/2000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2344 - categorical_accuracy: 0.9294\n",
      "Epoch 126/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1991 - categorical_accuracy: 0.9176\n",
      "Epoch 127/2000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1771 - categorical_accuracy: 0.9294\n",
      "Epoch 128/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2118 - categorical_accuracy: 0.9294\n",
      "Epoch 129/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2120 - categorical_accuracy: 0.8824\n",
      "Epoch 130/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1828 - categorical_accuracy: 0.9176\n",
      "Epoch 131/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2368 - categorical_accuracy: 0.8706\n",
      "Epoch 132/2000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.1718 - categorical_accuracy: 0.9176\n",
      "Epoch 133/2000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1805 - categorical_accuracy: 0.8941\n",
      "Epoch 134/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1648 - categorical_accuracy: 0.9412\n",
      "Epoch 135/2000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1796 - categorical_accuracy: 0.9176\n",
      "Epoch 136/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1475 - categorical_accuracy: 0.9765\n",
      "Epoch 137/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1722 - categorical_accuracy: 0.9176\n",
      "Epoch 138/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1709 - categorical_accuracy: 0.9294\n",
      "Epoch 139/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1873 - categorical_accuracy: 0.9176\n",
      "Epoch 140/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1665 - categorical_accuracy: 0.9529\n",
      "Epoch 141/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2329 - categorical_accuracy: 0.9059\n",
      "Epoch 142/2000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1923 - categorical_accuracy: 0.9529\n",
      "Epoch 143/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1779 - categorical_accuracy: 0.9529\n",
      "Epoch 144/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1419 - categorical_accuracy: 0.9529\n",
      "Epoch 145/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1533 - categorical_accuracy: 0.9412\n",
      "Epoch 146/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1373 - categorical_accuracy: 0.9529\n",
      "Epoch 147/2000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1540 - categorical_accuracy: 0.9529\n",
      "Epoch 148/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1509 - categorical_accuracy: 0.9294\n",
      "Epoch 149/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1583 - categorical_accuracy: 0.9412\n",
      "Epoch 150/2000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1393 - categorical_accuracy: 0.9529\n",
      "Epoch 151/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1482 - categorical_accuracy: 0.9294\n",
      "Epoch 152/2000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1552 - categorical_accuracy: 0.9412\n",
      "Epoch 153/2000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1554 - categorical_accuracy: 0.9294\n",
      "Epoch 154/2000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.1848 - categorical_accuracy: 0.9412\n",
      "Epoch 155/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1863 - categorical_accuracy: 0.9294\n",
      "Epoch 156/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1309 - categorical_accuracy: 0.9529\n",
      "Epoch 157/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1426 - categorical_accuracy: 0.9412\n",
      "Epoch 158/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1238 - categorical_accuracy: 0.9529\n",
      "Epoch 159/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2631 - categorical_accuracy: 0.9059\n",
      "Epoch 160/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.3426 - categorical_accuracy: 0.8588\n",
      "Epoch 161/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.2261 - categorical_accuracy: 0.9059\n",
      "Epoch 162/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1553 - categorical_accuracy: 0.9294\n",
      "Epoch 163/2000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2343 - categorical_accuracy: 0.9412\n",
      "Epoch 164/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2998 - categorical_accuracy: 0.8824\n",
      "Epoch 165/2000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2124 - categorical_accuracy: 0.9059\n",
      "Epoch 166/2000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1674 - categorical_accuracy: 0.9412\n",
      "Epoch 167/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2439 - categorical_accuracy: 0.9059\n",
      "Epoch 168/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1920 - categorical_accuracy: 0.9176\n",
      "Epoch 169/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1948 - categorical_accuracy: 0.9059\n",
      "Epoch 170/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1583 - categorical_accuracy: 0.9294\n",
      "Epoch 171/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1783 - categorical_accuracy: 0.9294\n",
      "Epoch 172/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1788 - categorical_accuracy: 0.9294\n",
      "Epoch 173/2000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1211 - categorical_accuracy: 0.9647\n",
      "Epoch 174/2000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.2187 - categorical_accuracy: 0.9412\n",
      "Epoch 175/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2358 - categorical_accuracy: 0.9059\n",
      "Epoch 176/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.2390 - categorical_accuracy: 0.8941\n",
      "Epoch 177/2000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1324 - categorical_accuracy: 0.9529\n",
      "Epoch 178/2000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1587 - categorical_accuracy: 0.9529\n",
      "Epoch 179/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1430 - categorical_accuracy: 0.9412\n",
      "Epoch 180/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1474 - categorical_accuracy: 0.9412\n",
      "Epoch 181/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1840 - categorical_accuracy: 0.9529\n",
      "Epoch 182/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1587 - categorical_accuracy: 0.9412\n",
      "Epoch 183/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1852 - categorical_accuracy: 0.9176\n",
      "Epoch 184/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1387 - categorical_accuracy: 0.9529\n",
      "Epoch 185/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1451 - categorical_accuracy: 0.9412\n",
      "Epoch 186/2000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.1856 - categorical_accuracy: 0.9059\n",
      "Epoch 187/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2548 - categorical_accuracy: 0.8941\n",
      "Epoch 188/2000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.2494 - categorical_accuracy: 0.9059\n",
      "Epoch 189/2000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.3101 - categorical_accuracy: 0.8941\n",
      "Epoch 190/2000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.2330 - categorical_accuracy: 0.9294\n",
      "Epoch 191/2000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.3231 - categorical_accuracy: 0.8706\n",
      "Epoch 192/2000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1926 - categorical_accuracy: 0.9294\n",
      "Epoch 193/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1392 - categorical_accuracy: 0.9529\n",
      "Epoch 194/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1770 - categorical_accuracy: 0.9412\n",
      "Epoch 195/2000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.1212 - categorical_accuracy: 0.9647\n",
      "Epoch 196/2000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.1667 - categorical_accuracy: 0.9412\n",
      "Epoch 197/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1304 - categorical_accuracy: 0.9412\n",
      "Epoch 198/2000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1177 - categorical_accuracy: 0.9647\n",
      "Epoch 199/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0892 - categorical_accuracy: 0.9765\n",
      "Epoch 200/2000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1298 - categorical_accuracy: 0.9529\n",
      "Epoch 201/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0857 - categorical_accuracy: 0.9765\n",
      "Epoch 202/2000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.1180 - categorical_accuracy: 0.9765\n",
      "Epoch 203/2000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0954 - categorical_accuracy: 0.9765\n",
      "Epoch 204/2000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0768 - categorical_accuracy: 0.9647\n",
      "Epoch 205/2000\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0755 - categorical_accuracy: 0.9647\n",
      "Epoch 206/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0723 - categorical_accuracy: 0.9647\n",
      "Epoch 207/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0810 - categorical_accuracy: 0.9647\n",
      "Epoch 208/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0573 - categorical_accuracy: 0.9647\n",
      "Epoch 209/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0744 - categorical_accuracy: 0.9647\n",
      "Epoch 210/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0646 - categorical_accuracy: 0.9765\n",
      "Epoch 211/2000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.1050 - categorical_accuracy: 0.9647\n",
      "Epoch 212/2000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0797 - categorical_accuracy: 0.9765\n",
      "Epoch 213/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1029 - categorical_accuracy: 0.9529\n",
      "Epoch 214/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1268 - categorical_accuracy: 0.9647\n",
      "Epoch 215/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2020 - categorical_accuracy: 0.8941\n",
      "Epoch 216/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.2455 - categorical_accuracy: 0.9059\n",
      "Epoch 217/2000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.1532 - categorical_accuracy: 0.9294\n",
      "Epoch 218/2000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1183 - categorical_accuracy: 0.9647\n",
      "Epoch 219/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1760 - categorical_accuracy: 0.9412\n",
      "Epoch 220/2000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1401 - categorical_accuracy: 0.9529\n",
      "Epoch 221/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0945 - categorical_accuracy: 0.9765\n",
      "Epoch 222/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.1080 - categorical_accuracy: 0.9647\n",
      "Epoch 223/2000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1327 - categorical_accuracy: 0.9529\n",
      "Epoch 224/2000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1232 - categorical_accuracy: 0.9647\n",
      "Epoch 225/2000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0704 - categorical_accuracy: 0.9765\n",
      "Epoch 226/2000\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.1082 - categorical_accuracy: 0.9647\n",
      "Epoch 227/2000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0822 - categorical_accuracy: 0.9765\n",
      "Epoch 228/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0797 - categorical_accuracy: 0.9647\n",
      "Epoch 229/2000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0841 - categorical_accuracy: 0.9765\n",
      "Epoch 230/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0627 - categorical_accuracy: 0.9765\n",
      "Epoch 231/2000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0897 - categorical_accuracy: 0.9765\n",
      "Epoch 232/2000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0633 - categorical_accuracy: 0.9765\n",
      "Epoch 233/2000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0508 - categorical_accuracy: 0.9765\n",
      "Epoch 234/2000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0780 - categorical_accuracy: 0.9765\n",
      "Epoch 235/2000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0574 - categorical_accuracy: 0.9882\n",
      "Epoch 236/2000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0750 - categorical_accuracy: 0.9647\n",
      "Epoch 237/2000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0712 - categorical_accuracy: 1.0000\n",
      "Epoch 238/2000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0970 - categorical_accuracy: 0.9647\n",
      "Epoch 239/2000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1037 - categorical_accuracy: 0.9529\n",
      "Epoch 240/2000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2329 - categorical_accuracy: 0.9176\n",
      "Epoch 241/2000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1569 - categorical_accuracy: 0.9529\n",
      "Epoch 242/2000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0943 - categorical_accuracy: 0.9647\n",
      "Epoch 243/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1133 - categorical_accuracy: 0.9529\n",
      "Epoch 244/2000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1071 - categorical_accuracy: 0.9647\n",
      "Epoch 245/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0945 - categorical_accuracy: 0.9765\n",
      "Epoch 246/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0467 - categorical_accuracy: 0.9882\n",
      "Epoch 247/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0807 - categorical_accuracy: 0.9765\n",
      "Epoch 248/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0607 - categorical_accuracy: 0.9765\n",
      "Epoch 249/2000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0524 - categorical_accuracy: 0.9882\n",
      "Epoch 250/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0508 - categorical_accuracy: 0.9882\n",
      "Epoch 251/2000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0491 - categorical_accuracy: 0.9765\n",
      "Epoch 252/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0506 - categorical_accuracy: 0.9765\n",
      "Epoch 253/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0451 - categorical_accuracy: 0.9882\n",
      "Epoch 254/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0409 - categorical_accuracy: 0.9882\n",
      "Epoch 255/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0429 - categorical_accuracy: 0.9882\n",
      "Epoch 256/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0401 - categorical_accuracy: 0.9882\n",
      "Epoch 257/2000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0437 - categorical_accuracy: 0.9765\n",
      "Epoch 258/2000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0506 - categorical_accuracy: 0.9765\n",
      "Epoch 259/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0513 - categorical_accuracy: 0.9765\n",
      "Epoch 260/2000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0547 - categorical_accuracy: 0.9882\n",
      "Epoch 261/2000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0411 - categorical_accuracy: 0.9882\n",
      "Epoch 262/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0616 - categorical_accuracy: 0.9882\n",
      "Epoch 263/2000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0645 - categorical_accuracy: 0.9765\n",
      "Epoch 264/2000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0386 - categorical_accuracy: 0.9882\n",
      "Epoch 265/2000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0359 - categorical_accuracy: 0.9882\n",
      "Epoch 266/2000\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0504 - categorical_accuracy: 0.9765\n",
      "Epoch 267/2000\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0383 - categorical_accuracy: 0.9882\n",
      "Epoch 268/2000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0424 - categorical_accuracy: 0.9765\n",
      "Epoch 269/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0385 - categorical_accuracy: 0.9882\n",
      "Epoch 270/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0451 - categorical_accuracy: 0.9765\n",
      "Epoch 271/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0571 - categorical_accuracy: 0.9765\n",
      "Epoch 272/2000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0427 - categorical_accuracy: 0.9882\n",
      "Epoch 273/2000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1266 - categorical_accuracy: 0.9529\n",
      "Epoch 274/2000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0555 - categorical_accuracy: 0.9765\n",
      "Epoch 275/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0525 - categorical_accuracy: 0.9882\n",
      "Epoch 276/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0825 - categorical_accuracy: 0.9882\n",
      "Epoch 277/2000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0778 - categorical_accuracy: 0.9882\n",
      "Epoch 278/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0492 - categorical_accuracy: 0.9882\n",
      "Epoch 279/2000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0461 - categorical_accuracy: 0.9882\n",
      "Epoch 280/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0515 - categorical_accuracy: 0.9882\n",
      "Epoch 281/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0523 - categorical_accuracy: 0.9882\n",
      "Epoch 282/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0494 - categorical_accuracy: 0.9882\n",
      "Epoch 283/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0527 - categorical_accuracy: 0.9882\n",
      "Epoch 284/2000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0391 - categorical_accuracy: 0.9882\n",
      "Epoch 285/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0442 - categorical_accuracy: 0.9882\n",
      "Epoch 286/2000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0354 - categorical_accuracy: 0.9882\n",
      "Epoch 287/2000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0295 - categorical_accuracy: 0.9882\n",
      "Epoch 288/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0296 - categorical_accuracy: 0.9882\n",
      "Epoch 289/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0354 - categorical_accuracy: 0.9882\n",
      "Epoch 290/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0283 - categorical_accuracy: 0.9882\n",
      "Epoch 291/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0268 - categorical_accuracy: 0.9882\n",
      "Epoch 292/2000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0336 - categorical_accuracy: 0.9882\n",
      "Epoch 293/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0579 - categorical_accuracy: 0.9882\n",
      "Epoch 294/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0387 - categorical_accuracy: 0.9882\n",
      "Epoch 295/2000\n",
      "3/3 [==============================] - 1s 168ms/step - loss: 0.0533 - categorical_accuracy: 0.9882\n",
      "Epoch 296/2000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.4090 - categorical_accuracy: 0.9059\n",
      "Epoch 297/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1283 - categorical_accuracy: 0.9529\n",
      "Epoch 298/2000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.1019 - categorical_accuracy: 0.9765\n",
      "Epoch 299/2000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0578 - categorical_accuracy: 0.9882\n",
      "Epoch 300/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0512 - categorical_accuracy: 0.9882\n",
      "Epoch 301/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0531 - categorical_accuracy: 0.9882\n",
      "Epoch 302/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0547 - categorical_accuracy: 0.9882\n",
      "Epoch 303/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0465 - categorical_accuracy: 0.9882\n",
      "Epoch 304/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0388 - categorical_accuracy: 0.9882\n",
      "Epoch 305/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0474 - categorical_accuracy: 0.9882\n",
      "Epoch 306/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0474 - categorical_accuracy: 0.9882\n",
      "Epoch 307/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0370 - categorical_accuracy: 0.9882\n",
      "Epoch 308/2000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0434 - categorical_accuracy: 0.9765\n",
      "Epoch 309/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0350 - categorical_accuracy: 0.9882\n",
      "Epoch 310/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0387 - categorical_accuracy: 0.9882\n",
      "Epoch 311/2000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0303 - categorical_accuracy: 0.9882\n",
      "Epoch 312/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0412 - categorical_accuracy: 0.9882\n",
      "Epoch 313/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0336 - categorical_accuracy: 0.9882\n",
      "Epoch 314/2000\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0272 - categorical_accuracy: 0.9882\n",
      "Epoch 315/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0485 - categorical_accuracy: 0.9882\n",
      "Epoch 316/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0272 - categorical_accuracy: 1.0000\n",
      "Epoch 317/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0394 - categorical_accuracy: 0.9765\n",
      "Epoch 318/2000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0373 - categorical_accuracy: 0.9765\n",
      "Epoch 319/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0587 - categorical_accuracy: 0.9765\n",
      "Epoch 320/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1356 - categorical_accuracy: 0.9529\n",
      "Epoch 321/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0868 - categorical_accuracy: 0.9647\n",
      "Epoch 322/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0457 - categorical_accuracy: 0.9765\n",
      "Epoch 323/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0315 - categorical_accuracy: 0.9882\n",
      "Epoch 324/2000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0340 - categorical_accuracy: 0.9882\n",
      "Epoch 325/2000\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0352 - categorical_accuracy: 0.9882\n",
      "Epoch 326/2000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0317 - categorical_accuracy: 0.9882\n",
      "Epoch 327/2000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0371 - categorical_accuracy: 0.9882\n",
      "Epoch 328/2000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0318 - categorical_accuracy: 0.9882\n",
      "Epoch 329/2000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0399 - categorical_accuracy: 0.9882\n",
      "Epoch 330/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0294 - categorical_accuracy: 0.9882\n",
      "Epoch 331/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0306 - categorical_accuracy: 0.9882\n",
      "Epoch 332/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0308 - categorical_accuracy: 0.9882\n",
      "Epoch 333/2000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0328 - categorical_accuracy: 0.9882\n",
      "Epoch 334/2000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0317 - categorical_accuracy: 0.9882\n",
      "Epoch 335/2000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0407 - categorical_accuracy: 0.9882\n",
      "Epoch 336/2000\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0461 - categorical_accuracy: 0.9765\n",
      "Epoch 337/2000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0353 - categorical_accuracy: 0.9882\n",
      "Epoch 338/2000\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0302 - categorical_accuracy: 0.9882\n",
      "Epoch 339/2000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0270 - categorical_accuracy: 0.9882\n",
      "Epoch 340/2000\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0257 - categorical_accuracy: 0.9882\n",
      "Epoch 341/2000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0251 - categorical_accuracy: 0.9882\n",
      "Epoch 342/2000\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0242 - categorical_accuracy: 0.9882\n",
      "Epoch 343/2000\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0240 - categorical_accuracy: 0.9882\n",
      "Epoch 344/2000\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0214 - categorical_accuracy: 0.9882\n",
      "Epoch 345/2000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0220 - categorical_accuracy: 1.0000\n",
      "Epoch 346/2000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0393 - categorical_accuracy: 0.9882\n",
      "Epoch 347/2000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0502 - categorical_accuracy: 0.9647\n",
      "Epoch 348/2000\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0206 - categorical_accuracy: 0.9882\n",
      "Epoch 349/2000\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0395 - categorical_accuracy: 0.9882\n",
      "Epoch 350/2000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0370 - categorical_accuracy: 0.9882\n",
      "Epoch 351/2000\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0182 - categorical_accuracy: 0.9882\n",
      "Epoch 352/2000\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0333 - categorical_accuracy: 0.9882\n",
      "Epoch 353/2000\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0305 - categorical_accuracy: 0.9882\n",
      "Epoch 354/2000\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0260 - categorical_accuracy: 0.9882\n",
      "Epoch 355/2000\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0288 - categorical_accuracy: 1.0000\n",
      "Epoch 356/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0282 - categorical_accuracy: 0.9882\n",
      "Epoch 357/2000\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0275 - categorical_accuracy: 0.9882\n",
      "Epoch 358/2000\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0295 - categorical_accuracy: 0.9882\n",
      "Epoch 359/2000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0251 - categorical_accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[96], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43mytrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_callback\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thomb\\anaconda3\\envs\\Base1\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\thomb\\anaconda3\\envs\\Base1\\lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\thomb\\anaconda3\\envs\\Base1\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\thomb\\anaconda3\\envs\\Base1\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\thomb\\anaconda3\\envs\\Base1\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\thomb\\anaconda3\\envs\\Base1\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thomb\\anaconda3\\envs\\Base1\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\thomb\\anaconda3\\envs\\Base1\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[1;32mc:\\Users\\thomb\\anaconda3\\envs\\Base1\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\thomb\\anaconda3\\envs\\Base1\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(xtrain,ytrain,epochs=2000,callbacks=tb_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 30, 64)            442112    \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 30, 128)           98816     \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 596675 (2.28 MB)\n",
      "Trainable params: 596675 (2.28 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 8 : Make Predictios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 258ms/step\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 9 : Save Weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thomb\\anaconda3\\envs\\Base1\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('action.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 10 : Evalution using Confusion Matrix and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 60ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix,accuracy_score\n",
    "yhat = model.predict(xtrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrue = np.argmax(ytrain,axis=1).tolist()\n",
    "ytrue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = np.argmax(yhat,axis=1).tolist()\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[57,  1],\n",
       "        [ 0, 27]],\n",
       "\n",
       "       [[56,  0],\n",
       "        [ 1, 28]],\n",
       "\n",
       "       [[56,  0],\n",
       "        [ 0, 29]]], dtype=int64)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(ytrue,yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.82352941176471"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytrue,yhat)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 11 : Test in real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [(245,117,16),(117,245,16),(16,117,245)]\n",
    "def prob_vis(res1,actions,input_frame,colors):\n",
    "    output_frame = input_frame.copy()\n",
    "    for num ,prob in enumerate(res1):\n",
    "        cv2.rectangle(output_frame,(0,60+num*40),(int(prob*100),90+num*40),colors[num],-1)\n",
    "        cv2.putText(output_frame,actions[num],(0,85+num*40),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2,cv2.LINE_AA)\n",
    "    return output_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(prob_vis(res1,actions,image,colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thomb\\AppData\\Local\\Temp\\ipykernel_10608\\5678894.py:37: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if np.unique(predictions[-10:]) == np.argmax(res):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 35ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "thanks\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "namaste\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "hello\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "res1 = []\n",
    "sequence = []\n",
    "sentence = []\n",
    "predictions = []\n",
    "threshold = 0.7\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5,min_tracking_confidence=0.5) as holistic:\n",
    "    \n",
    "    # min_detection - initially the holistic will detect the image with initial detection confidence\n",
    "    # min_tracking_confidence - holistic will detect the image with after initial  detection confidence\n",
    "    \n",
    "    while cap.isOpened():\n",
    "\n",
    "        # after capturing the video in real time the read() function return 2 values - 1 is return value and 2nd is the frame \n",
    "        res,frame = cap.read()\n",
    "\n",
    "        # Using a function to make detection \n",
    "        image,results = mediapipe_detection(frame,holistic)\n",
    "\n",
    "        # Draw landmarks in real time\n",
    "        draw_landmarks(image,results)\n",
    "        \n",
    "        \n",
    "        # Collet the values from already trained data from the disk\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "        # Prediction logic\n",
    "        \n",
    "        keypoints = extracted_values(results)\n",
    "        sequence.append(keypoints)\n",
    "        sequence = sequence[-30:]\n",
    "        \n",
    "        if len(sequence) == 30:\n",
    "            res1 = model.predict(np.expand_dims(sequence,axis=0))[0]\n",
    "            print(actions[np.argmax(res1)])        \n",
    "            predictions.append(np.argmax(res))\n",
    "            \n",
    "        # Visual logic \n",
    "        if np.unique(predictions[-10:]) == np.argmax(res):\n",
    "            if res1[np.argmax(res1)] > threshold:\n",
    "                if len(sentence)>0:\n",
    "                    if actions[np.argmax(res1)] != sentence[-1]:\n",
    "                        sentence.append(actions[np.argmax(res1)])\n",
    "                else:\n",
    "                    sentence.append(actions[np.argmax(res1)])\n",
    "                \n",
    "        if len(sentence) > 5:\n",
    "            sentence = sentence[-5:]\n",
    "        \n",
    "        image = prob_vis(res1,actions,image,colors)\n",
    "        \n",
    "        cv2.rectangle(image,(0,0),(640,40),(245,117,16),-1)\n",
    "        cv2.putText(image,' '.join(sentence),(3,30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2,cv2.LINE_AA)\n",
    "        \n",
    "\n",
    "        # Showing to screen    \n",
    "        cv2.imshow('Opencv_video',image)\n",
    "        # Breaking our infinite loop of capturing the video\n",
    "    \n",
    "        if cv2.waitKey(10) & 0xff == ord('q'):  # pressing q on keyboard will quite from video \n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Base1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
